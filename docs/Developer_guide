############################# Wi4MPI License ###########################
# `04/04/2016`                                                         #
# Copyright or (C) or Copr. Commissariat a l'Energie Atomique          #
#                                                                      #
# IDDN.FR.001.210022.000.S.P.2014.000.10800                            #
# This file is part of the Wi4MPI library.                             #
#                                                                      #
# This software is governed by the CeCILL-C license under French law   #
# and abiding by the rules of distribution of free software. You can   #
# use, modify and/ or redistribute the software under the terms of     #
# the CeCILL-C license as circulated by CEA, CNRS and INRIA at the     #
# following URL http://www.cecill.info.                                #
#                                                                      #
# The fact that you are presently reading this means that you have     #
# had knowledge of the CeCILL-C license and that you accept its        #
# terms.                                                               #
#                                                                      #
# Authors:                                                             #
#   - Delforge Tony <tony.delforge.tgcc@cea.fr>                        #
#   - Ducrot Vincent <vincent.ducrot.tgcc@cea.fr>                      #
#                                                                      #
########################################################################


:Authors:
    Tony Delforge (tony.delforge.tgcc@cea.fr)
    Vincent Ducrot (vincent.ducrot.tgcc@cea.fr)

Documentation développeur
=========================

Sommaire:
---------
1. Introduction
2. La bibliothèque
    1. Fonctionnement
    2. Implémentation
        1. Configuration de la bibliothèque
        2. Surcharge des symboles
        3. Code chooser ASM
        4. A_MPI_Function
        5. R_MPI_Function
        6. Thread safety
    3. Environnement d'exécution
    4. Les Fichiers
    5. Évolution
------------

INTRODUCTION
============
La bibliothèque WI4MPI fait de la traduction d'ABI entre les différentes souches MPI. Ceci permet de lancer un binaire non compatible avec la souche MPI chargée dans l'environnement d'exécution.

La bibliothèque est développée en C, dont le code est à 90% généré via un script python et des fichiers de configuration JSON contenant les dictionnaires des différentes fonctions MPI et ceux des différents mappers permettant la traduction. La version actuelle de la bibliothèque est thread safe, couvre la Norme MPI 1.3 avec le support de MPI-IO et est compatible C/C++/Fortran (Attention: l'API MPI C++ étant déprecated (cf:norme MPI) n'est pas supportée).

La bibliothèque
===============

Fonctionnement
--------------

Afin d'effectuer la traduction, la bibliothèque dissocie le coté applicatif de celui du runtime. 
Lors d'un appel à une fonction MPI coté applicatif (ex:MPI_Init), le véritable appel effectué se trouve être celui de WI4MPI (ex:A_MPI_Init). Cette fonction convertit les arguments, et effectue l'appel de la fonction (ex:LOCAL_MPI_Init) de la bibliothèque MPI sous-jacente (Runtime).
La conversion des arguments implique de manière générale une traduction des constantes (MPI_Status, MPI_Comm, MPI_Op, MPI_Info, ...) entre les différentes souches MPI. 

Implémentation
--------------

Configuration de la bibliothèque
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
La configuration de la bibliothèque est exécutée lors de son chargement, c'est à dire au startup du programme. On récupère les fonctions de la souche MPI cible (celle du runtime) dans des pointeurs, on initialise les spinlocks et on configure la table des constantes MPI (A_MPI vs R_MPI). **Attention** L'initialisation des spinlocks et de la table des constantes n'est effectuée que lors de l'appel du constructeur "wrapper_init".

void __attribute__((constructor)) wrapper_init
{

	void (*)lib_handle=dlopen(getenv("TRUE_MPI_LIB"),RTLD_NOW); **On ouvre la bibliothèque du Runtime (TRUE_MPI_LIB)**
	LOCAL_MPI_Function=dlsym(lib_handle,"PMPI_Function") **On charge les fonctions MPI (coté runtime) dans les pointeurs de fonctions associés**

	**Initialisation des spinlock**

	**Ajout des constantes A_MPI vs R_MPI dans la tables des constantes**

}

__attribute__((constructor)) permet de faire tout ce qui ce trouve dans wrapper_init au chargement de la bibliothèque (startup du programme)

Astuce: Dans un appel à dlsym, "lib_handle" peut être remplacé par "RTLD_NEXT" à condition que la souche MPI du runtime suive la bibliothèque WI4MPI dans le LD_PRELOAD

La bibliothèque en comprend actuellement trois:

- wrapper_init dans test_generation_wrapper.c (API C)
- wrapper_init_f dans wrapper.c (API Fortran)
- wrapper_init_c2ff2c dans c2f_f2c.c (API c2f/f2c) 


Surcharge des symboles
~~~~~~~~~~~~~~~~~~~~~~
Les appels à MPI sont remplacés par ceux de la bibliothèque wi4mpi grâce au chargement de cette dernière dans la variable d'environnement LD_PRELOAD et au rerouting suivant:

- #define A_MPI_Send PMPI_Send
- #pragma weak MPI_Send=PMPI_Send

L'implémentation de MPI-IO (ROMIO) fait appel à des fonctions internes MPI (PMPI_function), le fait de surcharger PMPI_function pose donc un problème majeur. Étant donné que les appels internes sont effectués coté runtime, aucune conversion n'est nécessaire. Néanmoins la surcharge des symboles implique un passage vers la fonction de conversion (A_MPI_function).
Afin de contourner ce problème, un code chooser à été mis en place. 
Le code chooser s'avère aussi être utile pour l'API Fortran. En effet, pour certaines souches MPI, l'API Fortran agit comme une interface appelant l'API C pour les appels MPI.

Code chooser ASM
~~~~~~~~~~~~~~~~
Si on vient du wrapper:

- On passe les arguments à l'appel sous-jacent (LOCAL_MPI_function)

Sinon

- On convertit les arguments
- On passe les arguments convertis à l'appel sous-jacent (LOCAL_MPI_function)

Pour savoir si on vient du wrapper une variable globale in_w à été mise en place.

- in_w=1 : on vient du wrapper
- in_w=0 : on vient de l'application

Le code chooser est écrit en asm de la facon suivante:

- .global PMPI_Function 
- .weak MPI_Function **Anciennement pragma weak MPI_function=PMPI_function**
- .set MPI_function,PMPI_Function **Anciennement define A_MPI_Send PMPI_Send**
- .extern in_w 
- .extern A_MPI_Function
- .extern R_MPI_Function
- .type PMPI_Function,@function
- .text
- PMPI_Function:
- push %rbp **prologue**
- mov %rsp, %rbp **prologue**
- sub $0x20, %rsp **réservation de la stack pour 4 arguments das ce cas (attention rsp+8%16 =0)**
- mov %rdi, -0x8(%rbp) **sauvegarde des registres**
- mov %rsi, -0x10(%rbp) **sauvegarde des registres**
- mov %rdx, -0x18(%rbp) **sauvegarde des registres**
- mov %rcx, -0x20(%rbp) **sauvegarde des registres**
- .byte 0x66 **alignement pour la santé du linker**
- leaq in_w@tlsgd(%rip), %rdi **récupération de l'addresse in_w initialisée dans une TLS (Thread Local Storage)**
- .value 0x6666 **alignement pour la santé du linker**
- rex64 **alignement pour la santé du linker**
- call __tls_get_addr@PLT **récupération de in_w dans rax**
- mov -0x8(%rbp), %rdi **restauration des registres**
- mov -0x10(%rbp), %rsi **restauration des registres**
- mov -0x18(%rbp), %rdx **restauration des registres**
- mov -0x20(%rbp), %rcx **restauration des registres**
- leave **restauration de la stack**
- cmpl $0x0, 0x0(%rax) **test sur in_w (on vient du wrapper ou pas)**
- jne inwrap_MPI_Function
- jmp (*)A_MPI_Function@GOTPCREL(%rip) **go to A_MPI_Function**
- inwrap_MPI_Function:
- jmp (*)R_MPI_Function@GOTPCREL(%rip) **go to R_MPI_Function**
- .size PMPI_Function,.-PMPI_Function

A_MPI_Function
~~~~~~~~~~~~~~
La conversion se fait à l'aide de mappers présent dans mappers.h. La plupart d'entre eux s'appuient sur plusieurs tables de hashages présentes dans new_utils.* et new_utils_fn.*.
Il y a une table pour gérer la correspondance des constantes, et une table par type MPI pour assurer la traduction.
Les différents type étant:

- MPI_Comm
- MPI_Datatype
- MPI_Errhandler
- MPI_Group
- MPI_Op
- MPI_Request **Séparé en 2 tables, afin de dissocier les requêtes persistantes des requêtes non-bloquantes**
- MPI_File

Les tables présentent dans new_utils_fn.* concernent les traductions des fonctions suivantes:

- MPI_Handler_function
- MPI_Comm_copy_attr_function
- MPI_Comm_delete_function
- MPI_Type_delete_function
- MPI_Comm_errhandler_function
- MPI_File_errhandler_function 

Exemple:

A_MPI_Send(void * buf,int count,A_MPI_Datatype datatype,int dest,int tag,A_MPI_Comm comm)

{

	void * buf_tmp;

	const_buffer_conv_a2r(&buf,&buf_tmp); **mapper**

	R_MPI_Datatype datatype_tmp;

	datatype_conv_a2r(&datatype,&datatype_tmp); **mapper**

	int dest_tmp;

	dest_conv_a2r(&dest,&dest_tmp); **mapper**

	int tag_tmp;

	tag_conv_a2r(&tag,&tag_tmp); **mapper**

	R_MPI_Comm comm_tmp;

	comm_conv_a2r(&comm,&comm_tmp); **mapper**

	int ret_tmp= LOCAL_MPI_Send( buf_tmp, count, datatype_tmp, dest_tmp, tag_tmp, comm_tmp); **Appel à MPI_Send coté runtime**

	return error_code_conv_r2a(ret_tmp); **conversion du retour d'erreur**

}


R_MPI_Function
~~~~~~~~~~~~~~
Rien de spécial ici, les arguments sont directement passés à l'appel de la fonction MPI coté runtime.

int R_MPI_Send(void * buf,int count,R_MPI_Datatype datatype,int dest,int tag,R_MPI_Comm comm)
{

	int ret_tmp= LOCAL_MPI_Send( buf, count, datatype, dest, tag, comm);

	return ret_tmp;

}

Thread_safety
~~~~~~~~~~~~~
Afin de rendre le code thread safe, la variable in_w (permettant de detecter si l'on vient du wrapper ou de l'application) est protégée par une TLS:

- __thread int in_w=0; (test_wrapper_generation.c:118)
- extern __thread int in_w; (wrapper.c:7)
- extern __thread int in_w; (c2f_f2c.c:6) || (c2f_f2c.c:1149)

Pour protéger les tables, les spinlock ont été utilisés (cf :thread_safety.h):

- #define lock_dest(a) pthread_spin_destroy(a)
- #define lock_init(a) pthread_spin_init(a,PTHREAD_PROCESS_PRIVATE)
- #define lock(a)  pthread_spin_lock(a)
- #define unlock(a) pthread_spin_unlock(a)
- typedef  pthread_spinlock_t (*)table_lock_t;

Environnement d'exécution (Lire la doc utilisateur avant de commencer cette section)
------------------------------------------------------------------------------------

WI4MPI configure son environnement seulement pour l'exécution via le script wi4mpi.

- Il set la variable d'environnement LD_PRELOAD avec le preload de l'utilisateur plus le chemin vers la bibliothèque correspondant à la conversion désirée.

- Il set la variable TRUE_MPI_LIB au chemin de la souche MPI cible

- Il export la variable LD_LIBRARY_PATH en ajoutant le chemin vers les bibliothèques vides nécessaire au bon déroulement du code.

Le problème avec ce protocole, est la perte potentiel de certains symboles MPI. Pour résoudre ce problème, la bibliothèque WI4MPI exporte ces symboles. (cf test_generation_wrapper.c).

exemple :

#if defined(OMPI_INTEL)

char ompi_mpi_comm_null[1024];

...

#endif



Les fichiers
------------

- mappers.h : contient les mappers pour la traduction
- new_utils.* et new_utils_fn.*: contient les tables
- test_wrapper_generation.c : code généré contenant le code chooser ASM, A_MPI_Function, R_MPI_Function, et l'initialisation de la bibliothèque (void __attribute__((constructor)) wrapper_init).
- wrapper.c : code généré contenant l'API Fortran , ainsi que l'initialisation des pointeurs ( void __attribute__((constructor)) wrapper_init_f)
- c2f_f2c.c : code généré contenant l'API c2f/f2c , ainsi que l'initialisation des pointeurs ( void __attribute__((constructor)) wrapper_init_c2ff2c)
- thread_safety.h : contient la définition des spin_lock
- optimisation.h : gère l'utilisation des tables
- app_mpi.h/run_mpi.h : Contiennent les constantes MPI.
- app/$FROM_$TO/app_mpi.h : contient les constantes C côté applicatif 
- app/$FROM_$TO/run_mpi.h : contient les constantes C côté runtime
- $FROM_$TO/wrapper_f.h : contient les constantes Fortran
- manual_wrapper.h : contient les fonctions/mappers écrit(es) à la main.

Évolution
---------

- Étendre la couverture MPI de WI4MPI:
  
  - Toutes les fonctions actuellement présentes dans la norme MPI 3.1 sont référencées dans functions.json. De ce fait, pour étendre la couverture de la bibliothèque WI4MPI il suffit de rajouter le nom des fonctions manquantes dans func_list.txt (cf chapitre générateur), puis de regénérer test_generation_wrapper.c avec la commande : python generator.py
  - Vis a vis des mappers, il faut rajouter ceux ne couvrant pas les types exclusivement présent dans les normes > 1.3 . C'est à dire rajouter les r2a/a2r qui vont bien dans mappers.h, et editer mappers.json en fonction des noms définis.

- Pour étendre l'utilisation de WI4MPI à plusieurs souche MPI:

  - Actuellement, le code de WI4MPI est compatible avec les conversions suivantes:
     - OMPI_OMPI : **Header généré**
     - INTEL_INTEL : **Header généré**
     - MPC_MPC : **Header non généré**
     - HPMPI_HPMPI : **Header non généré**
     - INTEL_OMPI : **Header généré**
     - OMPI_INTEL : **Header généré**
     - INTEL_MPC : **Header non généré**
     - MPC_INTEL : **Header non généré**
     - OMPI_MPC : **Header non généré**
     - MPC_OMPI : **Header non généré**
     - INTEL_HPMPI : **Header non généré**
     - HPMPI_INTEL : **Header non généré**
     - OMPI_HPMPI : **Header non généré**
     - HPMPI_OMPI : **Header non généré**
     - MPC_HPMPI : **Header non généré**
     - HPMPI_MPC : **Header non généré**
  - Générer les headers (.h) associés aux différentes conversions:
     - app_mpi.h : sed 's/MPI/A_MPI/g' mpi.h | grep sed 's/PA_MPI/A_PMPI/g'
        - cette commande effectue le plus gros du travail, pour le reste, il faut se laisser guider par le compilateur
     - run_mpi.h : sed 's/MPI/R_MPI/g' mpi.h | grep sed 's/PR_MPI/R_PMPI/g'
     - Pour les conversions de type A vers A (OMPI_OMPI, MPC_MPC, ...) attention aux redéfinitions de macros lors de la génération des headers.
  - Dans le cas ou l'on désire rajouter de nouvelles conversions:
     - Dans mappers.h, rajouter aux fonctions suivantes la compatibilité associée aux différentes conversions:
        - status_prt_conv_a2r
        - status_prt_conv_r2a
        - status_tab_conv_r2a


